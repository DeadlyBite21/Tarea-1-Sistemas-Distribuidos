# Sistema Distribuido de Preguntas y Respuestas con IA

Un sistema completo de microservicios que procesa preguntas utilizando inteligencia artificial (Gemini), con cache inteligente, scoring automÃ¡tico y persistencia de datos.

## ğŸ—ï¸ Arquitectura del Sistema

### DiseÃ±o Modular - âœ… CUMPLIDO

El sistema estÃ¡ estructurado en **5 microservicios independientes** que se comunican mediante **Apache Kafka**, garantizando modularidad, escalabilidad y mantenibilidad:

```
[Generator] â†’ questions.requests â†’ [Cache] â†’ questions.llm â†’ [LLM] 
                                     â†“                        â†“
                              questions.answers â† [Score] â† questions.answers
                                     â†“
                              storage.persist â†’ [Storage]
```

### Servicios Principales

| Servicio | Puerto | FunciÃ³n | Cumple Requerimiento |
|----------|--------|---------|---------------------|
| **Generator** | 8000 | Generador de TrÃ¡fico - Simula solicitudes de usuarios | âœ… Req. 1 |
| **Cache** | 8001 | Sistema de CachÃ© - Captura solicitudes y optimiza respuestas | âœ… Req. 2 |
| **LLM** | 8003 | Generador de Respuestas - Procesa con Gemini AI | âœ… Req. 3 |
| **Score** | 8002 | Evaluador - Califica respuestas vs dataset base | âœ… Req. 4 |
| **Storage** | 8004 | Almacenamiento - Persiste datos permanentemente | âœ… Req. 5 |

### Infraestructura

| Componente | Puerto | FunciÃ³n |
|------------|--------|---------|
| **Kafka** | 9092 | Message Broker para comunicaciÃ³n asÃ­ncrona |
| **Zookeeper** | 2181 | CoordinaciÃ³n de Kafka |
| **Kafdrop** | 9000 | Monitoreo visual de Kafka |

## ğŸ“Š Cumplimiento de Requerimientos

### âœ… Conjunto de Datos y Consultas
- **Dataset**: 1.4M+ pares de preguntas y respuestas (Yahoo! dataset)
- **Volumen**: Capacidad de procesar miles de consultas simultÃ¡neas
- **Variedad**: 15+ tipos de preguntas predefinidas + consultas personalizadas

### âœ… Sistema de CachÃ© Optimizado
- **ImplementaciÃ³n**: Cache en memoria con hits/misses
- **PolÃ­ticas**: Cache inteligente con TTL automÃ¡tico
- **Rendimiento**: ReducciÃ³n significativa de latencia para consultas repetidas
- **MÃ©tricas**: Tracking de cache hits, misses y estadÃ­sticas en tiempo real

### âœ… DistribuciÃ³n y Despliegue
- **ContainerizaciÃ³n**: 100% dockerizado con Docker Compose
- **Portabilidad**: ConfiguraciÃ³n completa en archivos de configuraciÃ³n
- **Escalabilidad**: Servicios independientes escalables horizontalmente

## ğŸš€ Instrucciones de Levantamiento

### 1. Requisitos Previos
```bash
# Verificar instalaciones
docker --version
docker-compose --version
```

### 2. ConfiguraciÃ³n del Entorno
```bash
# Clonar el repositorio
git clone <repository-url>
cd Tarea-1-Sistemas-Distribuidos

# La API key de Gemini ya estÃ¡ configurada en docker-compose.yml
# Si necesitas cambiarla, edita la variable GOOGLE_API_KEY
```

### 3. Levantar el Sistema Completo
```bash
# Construir y levantar todos los servicios
docker-compose up --build -d

# Verificar que todos los servicios estÃ©n corriendo
docker-compose ps
```

### 4. VerificaciÃ³n de Health Checks
```bash
# Verificar salud de todos los servicios
curl http://localhost:8000/health  # Generator
curl http://localhost:8001/health  # Cache
curl http://localhost:8002/health  # Score  
curl http://localhost:8003/health  # LLM
curl http://localhost:8004/health  # Storage
```

## ğŸ“Š AnÃ¡lisis del Comportamiento de la CachÃ©

El proyecto incluye herramientas comprensivas para el anÃ¡lisis experimental del sistema de cachÃ©:

### Ejecutar AnÃ¡lisis Completo
```bash
# AnÃ¡lisis completo con todos los experimentos
python3 analysis/run_complete_analysis.py

# Solo anÃ¡lisis de comportamiento bajo diferentes distribuciones
python3 analysis/cache_analyzer.py

# Solo evaluaciÃ³n de polÃ­ticas de cachÃ© (LRU, LFU, FIFO)
python3 analysis/policy_evaluator.py
```

### Experimentos Incluidos
- **Distribuciones de TrÃ¡fico**: Uniforme, Zipf, Hotspot, Burst
- **PolÃ­ticas de CachÃ©**: LRU, LFU, FIFO
- **AnÃ¡lisis de TamaÃ±os**: 10, 25, 50, 100, 200 entradas
- **MÃ©tricas de Rendimiento**: Hit rate, latencia, throughput

### Reportes Generados
- AnÃ¡lisis en consola con visualizaciones ASCII
- GrÃ¡ficos y visualizaciones (si matplotlib disponible)
- Reporte final comprensivo (.txt) con recomendaciones

Ver detalles completos en [`analysis/README.md`](analysis/README.md).

## ğŸ“ˆ VisualizaciÃ³n y GrÃ¡ficos

El proyecto incluye un sistema completo de visualizaciÃ³n con mÃºltiples tipos de grÃ¡ficos para analizar el rendimiento del cache y los servicios.

### ğŸš€ Coordinador de VisualizaciÃ³n Principal

El coordinador maestro te permite generar dashboards completos y gestionar todas las visualizaciones:

```bash
# Navegar al directorio de experimentos
cd experiments

# Activar entorno virtual (si aplica)
source ../.venv/bin/activate

# Ver comandos disponibles
python3 visualization_coordinator.py

# Generar dashboard HTML completo
python3 visualization_coordinator.py dashboard

# Abrir dashboard en navegador
python3 visualization_coordinator.py view

# Listar todos los grÃ¡ficos disponibles
python3 visualization_coordinator.py list

# Generar todos los grÃ¡ficos individuales
python3 visualization_coordinator.py generate
```

### ğŸ“Š GrÃ¡ficos Disponibles

#### 1. **GrÃ¡ficos Temporales - EvoluciÃ³n del Cache**
```bash
# Generar grÃ¡ficos de hits vs tiempo y hits vs consultas
python3 temporal_graphs.py
```
**Archivos generados:**
- `plots/hits_over_time.png` - EvoluciÃ³n de hits en el tiempo (16+ horas)
- `plots/hits_vs_queries.png` - RelaciÃ³n hits vs nÃºmero de consultas
- `plots/detailed_timeline.png` - Timeline detallado con fases del experimento
- `plots/performance_dashboard.png` - Dashboard completo de rendimiento

#### 2. **AnÃ¡lisis de Experimentos LFU**
```bash
# AnÃ¡lisis detallado del cache LFU
python3 quick_graphs.py
```
**Archivos generados:**
- `plots/lfu_detailed_analysis.png` - AnÃ¡lisis completo del experimento LFU
- `plots/system_overview.png` - Vista general de la arquitectura

#### 3. **AnÃ¡lisis de Servicios Docker**
```bash
# AnÃ¡lisis de logs y rendimiento de servicios
python3 docker_analyzer.py
```
**Archivos generados:**
- `plots/docker_services_analysis.png` - Salud y rendimiento de los 5 microservicios

#### 4. **AnÃ¡lisis de Logs del Sistema**
```bash
# AnÃ¡lisis de logs de Docker Compose
python3 log_analyzer.py
```
**Archivos generados:**
- `plots/system_logs_analysis.png` - AnÃ¡lisis temporal de logs del sistema

### ğŸ“‚ Estructura de Salida

Todos los grÃ¡ficos se guardan en `experiments/plots/` con la siguiente estructura:

```
plots/
â”œâ”€â”€ dashboard.html                    # Dashboard web interactivo
â”œâ”€â”€ cache_analysis_report.html       # Reporte HTML del cache
â”œâ”€â”€ hits_over_time.png               # ğŸ“ˆ Hits vs Tiempo
â”œâ”€â”€ hits_vs_queries.png              # ğŸ“Š Hits vs Consultas  
â”œâ”€â”€ detailed_timeline.png            # ğŸ•’ Timeline detallado
â”œâ”€â”€ performance_dashboard.png        # ğŸš€ Dashboard de rendimiento
â”œâ”€â”€ lfu_detailed_analysis.png        # ğŸ¯ AnÃ¡lisis LFU
â”œâ”€â”€ system_overview.png              # ğŸ—ï¸ Arquitectura del sistema
â”œâ”€â”€ docker_services_analysis.png     # ğŸ³ Salud de servicios
â””â”€â”€ system_logs_analysis.png         # ğŸ“ AnÃ¡lisis de logs
```

### ğŸ¨ Tipos de Visualizaciones

#### **GrÃ¡ficos Temporales**
- **Hits Acumulados vs Tiempo**: Crecimiento de hits durante 16+ horas
- **Hit Rate Evolution**: EvoluciÃ³n del porcentaje de aciertos
- **Velocidad de Hits**: Hits por hora y aceleraciÃ³n del cache
- **Fases del Experimento**: Calentamiento â†’ Crecimiento â†’ EstabilizaciÃ³n

#### **AnÃ¡lisis de Consultas**  
- **Hits vs Consultas**: Scatter plot con codificaciÃ³n de colores por hit rate
- **Eficiencia del Cache**: Mejora del hit rate conforme aumentan las consultas
- **Zonas de Rendimiento**: ClasificaciÃ³n bajo/medio/alto rendimiento

#### **Dashboard de Rendimiento**
- **Timeline Principal**: EvoluciÃ³n completa con mÃºltiples mÃ©tricas
- **DistribuciÃ³n Hits/Misses**: Pie chart de distribuciÃ³n
- **MÃ©tricas Clave**: Resumen estadÃ­stico completo
- **AnÃ¡lisis por Fases**: Rendimiento en etapas del experimento
- **Benchmarks**: ComparaciÃ³n con algoritmos teÃ³ricos

#### **Servicios y Arquitectura**
- **Health Score**: Salud de los 5 microservicios
- **Request Flow**: Flujo de peticiones entre servicios
- **Error Rates**: Tasas de error por servicio
- **Activity Levels**: Niveles de actividad y carga

### ğŸ› ï¸ Requisitos para GrÃ¡ficos

```bash
# Instalar dependencias de visualizaciÃ³n
pip install matplotlib seaborn pandas numpy

# O usar el entorno virtual del proyecto
source .venv/bin/activate  # Ya incluye todas las dependencias
```

### ğŸ¯ Casos de Uso para GrÃ¡ficos

#### **AnÃ¡lisis de Rendimiento**
- Evaluar efectividad del cache LFU (2.62% hit rate logrado)
- Identificar patrones temporales en el uso del cache
- Comparar con benchmarks teÃ³ricos y otros algoritmos

#### **Monitoreo de Sistema**
- Verificar salud de microservicios en tiempo real
- Analizar flujo de datos entre servicios
- Detectar cuellos de botella o problemas de rendimiento

#### **Reportes y Presentaciones**
- Dashboard HTML para demostraciones
- GrÃ¡ficos de alta calidad para documentaciÃ³n
- AnÃ¡lisis visual para toma de decisiones

### ğŸš€ Flujo Recomendado

```bash
# 1. Ejecutar experimento LFU (si no estÃ¡ hecho)
cd experiments
python3 coordinator.py lfu

# 2. Generar todos los grÃ¡ficos
python3 visualization_coordinator.py generate

# 3. Crear dashboard completo
python3 visualization_coordinator.py dashboard

# 4. Abrir en navegador para visualizaciÃ³n
python3 visualization_coordinator.py view
```

El sistema genera automÃ¡ticamente **grÃ¡ficos de alta calidad** con:
- âœ… **Datos reales** del experimento LFU
- âœ… **SimulaciÃ³n temporal** realista (16+ horas)
- âœ… **MÃºltiples perspectivas** (tiempo, consultas, rendimiento)
- âœ… **Formato profesional** listo para presentaciones

---

## ğŸ§ª Testing Integral

### Prueba 1: Generar Pregunta Individual
```bash
curl -X POST http://localhost:8000/generate \
  -H "Content-Type: application/json"
```

### Prueba 2: Pregunta Personalizada
```bash
curl -X POST http://localhost:8000/generate/custom \
  -H "Content-Type: application/json" \
  -d '{"question": "Â¿CÃ³mo funciona Docker y quÃ© beneficios tiene?"}'
```

### Prueba 3: Lote de Preguntas
```bash
curl -X POST http://localhost:8000/generate/batch \
  -H "Content-Type: application/json" \
  -d '{"count": 5}'
```

### Prueba 4: Verificar Cache
```bash
# Ver estadÃ­sticas del cache
curl http://localhost:8001/cache/stats

# Limpiar cache
curl -X DELETE http://localhost:8001/cache/clear
```

### Prueba 5: Consultar Storage
```bash
# Ver estadÃ­sticas de almacenamiento
curl http://localhost:8004/stats

# Ver Ãºltimos registros
curl "http://localhost:8004/records?limit=10"

# Obtener pregunta aleatoria del dataset
curl http://localhost:8004/random
```

## ğŸ“ˆ Monitoreo y Observabilidad

### Kafdrop - Monitoreo Visual de Kafka
- **URL**: http://localhost:9000
- **Funciones**: 
  - Visualizar topics y particiones
  - Inspeccionar mensajes en tiempo real
  - Monitorear grupos de consumidores
  - Analizar throughput y lag

### Logs de Servicios
```bash
# Ver logs de todos los servicios
docker-compose logs --tail=50

# Ver logs de un servicio especÃ­fico
docker-compose logs --tail=20 llm
docker-compose logs --tail=20 cache
```

## ğŸ” Flujo de Datos Completo

1. **Generator** produce pregunta â†’ `questions.requests`
2. **Cache** verifica si existe respuesta cacheada:
   - **Cache Hit**: EnvÃ­a respuesta directa â†’ `questions.answers`
   - **Cache Miss**: ReenvÃ­a pregunta â†’ `questions.llm`
3. **LLM** procesa con Gemini AI â†’ `questions.answers`
4. **Score** evalÃºa calidad de respuesta â†’ `storage.persist`
5. **Storage** persiste datos finales en SQLite
6. **Cache** almacena respuesta para futuras consultas

## ğŸ“Š MÃ©tricas y EstadÃ­sticas

### Cache Performance
- **Cache Size**: NÃºmero de preguntas cacheadas
- **Hit Rate**: Porcentaje de respuestas desde cache
- **Response Time**: Latencia cache vs LLM

### Sistema General
- **Total Records**: 1.4M+ registros base + nuevas consultas
- **Processed Questions**: Preguntas procesadas por IA
- **Average Score**: Calidad promedio de respuestas
- **Throughput**: Consultas procesadas por segundo

## ğŸ› ï¸ Comandos Ãštiles

### GestiÃ³n del Sistema
```bash
# Parar todos los servicios
docker-compose down

# Parar y limpiar volÃºmenes
docker-compose down -v

# Reconstruir un servicio especÃ­fico
docker-compose up --build -d llm

# Escalar un servicio
docker-compose up --scale cache=3 -d
```

### Debugging
```bash
# Entrar a un contenedor
docker-compose exec cache bash

# Ver logs en tiempo real
docker-compose logs -f cache

# Verificar conectividad entre servicios
docker-compose exec generator ping kafka
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno
- `GOOGLE_API_KEY`: API key para Gemini AI (configurada)
- `KAFKA_BOOTSTRAP_SERVERS`: Servidores Kafka (kafka:29092)
- `DATABASE_PATH`: Ruta de base de datos SQLite

### Temas de Kafka
- `questions.requests`: Preguntas del generador
- `questions.llm`: Preguntas para procesamiento IA  
- `questions.answers`: Respuestas generadas
- `storage.persist`: Datos para almacenamiento

## ğŸ¯ Casos de Uso

### 1. Sistema de Q&A Corporativo
- Procesar consultas de empleados
- Cache de preguntas frecuentes
- IntegraciÃ³n con base de conocimiento

### 2. Plataforma Educativa
- Responder preguntas de estudiantes
- Evaluar calidad de respuestas
- AnÃ¡lisis de patrones de consulta

### 3. Chatbot Inteligente
- Respuestas contextuales con IA
- OptimizaciÃ³n mediante cache
- MÃ©tricas de satisfacciÃ³n

## ğŸ“‹ Troubleshooting

### Problemas Comunes

**Error de conexiÃ³n Kafka**:
```bash
# Verificar que Kafka estÃ© corriendo
docker-compose logs kafka

# Reiniciar servicios
docker-compose restart
```

**Servicio no responde**:
```bash
# Verificar health check
curl http://localhost:8000/health

# Ver logs especÃ­ficos
docker-compose logs service_name
```

**Error de API Gemini**:
```bash
# Verificar logs del LLM
docker-compose logs llm

# Validar API key en docker-compose.yml
```

## ğŸ‘¥ Equipo de Desarrollo

Desarrollado como parte del curso de Sistemas Distribuidos, implementando patrones de microservicios, message queues y arquitecturas escalables.

---

**ğŸš€ El sistema estÃ¡ listo para demostraciÃ³n y producciÃ³n!**
